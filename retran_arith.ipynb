{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76b70ad0",
   "metadata": {},
   "source": [
    "# Attention Ain't All, Recurent Transformer (ReTran), ACL 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842f5287",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7564a825",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random, math, torch, time, warnings, torch_optimizer, torchtune, datasets\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from matplotlib.ticker import ScalarFormatter, LogLocator\n",
    "\n",
    "plt.rcParams.update({'font.size':20})\n",
    "device = torch.device(\"cuda\")\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "\n",
    "def timer(func, *args, **kwargs):\n",
    "    start_time = time.perf_counter()\n",
    "    result = func(*args, **kwargs)\n",
    "    end_time = time.perf_counter()\n",
    "    \n",
    "    elapsed_time = end_time - start_time\n",
    "    return elapsed_time, result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a92be0",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3699e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vocab\n",
    "PAD = '<pad>'\n",
    "START = '<start>'\n",
    "STOP = '<stop>'\n",
    "SEP = '='\n",
    "vocab = [START, SEP, STOP, PAD] + [str(i) for i in range(10)] + ['-', '+', '*', '(', ')']\n",
    "\n",
    "#Translates from a string to a pytorch tensor using a vocab\n",
    "def encodeVocab(string, pad_length):\n",
    "    return torch.tensor([vocab.index(START)]\n",
    "                        + [vocab.index(i) for i in string]\n",
    "                        + [vocab.index(STOP)]\n",
    "                        + [vocab.index(PAD)] * (pad_length - len(string)),\n",
    "                        dtype = torch.long)\n",
    "\n",
    "#Translates from a pytorch tensor to a string using a vocab\n",
    "def decodeVocab(tensor):\n",
    "    ans = \"\"\n",
    "    for i in tensor:\n",
    "        if vocab[i] == START or vocab[i] == PAD:\n",
    "            continue\n",
    "        if vocab[i] == STOP:\n",
    "            break\n",
    "        ans += vocab[i]\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc844eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PROBLEM GENERATION\n",
    "#Define rules for a context free grammar\n",
    "rules = {}\n",
    "def addRule(left_hand, right_hand, probability):\n",
    "    if left_hand in rules:\n",
    "        rules[left_hand].append((right_hand, probability))\n",
    "    else:\n",
    "        rules[left_hand] = [(right_hand, probability)]\n",
    "\n",
    "#Create a probabilistic free grammar to generate math problems\n",
    "addRule('EQ', ['VAL', 'OP', 'VAL'], 0.5)\n",
    "addRule('EQ', ['(', 'VAL', 'OP', 'VAL', ')'], 0.5)\n",
    "addRule('VAL', ['EQ'], 0.46)\n",
    "addRule('VAL', ['NUM'], 0.54)\n",
    "addRule('OP', ['+'], 0.35)\n",
    "addRule('OP', ['-'], 0.35)\n",
    "addRule('OP', ['*'], 0.3)\n",
    "addRule('NUM', ['0'], 0.05)\n",
    "addRule('NUM', ['NUMH', 'NUMT'], 0.95)\n",
    "for i in range(1, 10):\n",
    "    addRule('NUMH', [str(i)], 1.0 / 18)\n",
    "    addRule('NUMH', ['-', str(i)], 1.0 / 18)\n",
    "\n",
    "for i in range(10):\n",
    "    addRule('NUMT', [str(i), 'NUMT'], 0.02)\n",
    "addRule('NUMT', [], 0.8)\n",
    "\n",
    "#Choose a random rule to expand\n",
    "def selectRule(left_hand):\n",
    "    selector = random.random()\n",
    "    for i in rules[left_hand]:\n",
    "        selector -= i[1]\n",
    "        if(selector < 0):\n",
    "            return i[0]\n",
    "    raise Exception(\"Improper rule probabilities\")\n",
    "\n",
    "#Generate a problem using the context free grammar with certain bounds\n",
    "def generateProblem(min_in_len, max_in_len, min_out_len, max_out_len):\n",
    "    while(True):\n",
    "        stack = ['EQ']\n",
    "        index = 0\n",
    "        while(index < len(stack) and len(stack) <= (max_in_len + 2)):\n",
    "            if index > 0 and stack[index] == '-' :\n",
    "                if stack[index - 1] == '-':\n",
    "                    stack.pop(index)\n",
    "                    stack[index - 1] = '+'\n",
    "                elif stack[index - 1] == '+':\n",
    "                    stack.pop(index)\n",
    "                    stack[index - 1] = '-'\n",
    "            if stack[index] in rules:\n",
    "                stack = stack[:index] + selectRule(stack[index]) + stack[index + 1:]\n",
    "            else:\n",
    "                index += 1\n",
    "\n",
    "        prob = ''.join(stack)\n",
    "        if(len(prob) >= min_in_len and len(prob) <= max_in_len):\n",
    "            soln = str(eval(prob))\n",
    "            if(len(soln) >= min_out_len and len(soln) <= max_out_len):\n",
    "                return prob, soln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957b2d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decoder only arithmetic dataset\n",
    "class ArithDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, samples, seed=0, min_in_len=1, max_in_len=20, min_out_len=1, max_out_len=6):\n",
    "        prob_check = set()\n",
    "        self.combined = []\n",
    "        self.problem_lens = []\n",
    "        self.combined_lens = []\n",
    "        \n",
    "        random.seed(seed)\n",
    "        while(len(prob_check) < samples):\n",
    "            prob, soln = generateProblem(min_in_len=min_in_len,\n",
    "                                          max_in_len=max_in_len,\n",
    "                                          min_out_len=min_out_len,\n",
    "                                          max_out_len=max_out_len)\n",
    "            if prob not in prob_check:\n",
    "                self.combined.append(encodeVocab(prob + SEP + soln, max_in_len + max_out_len + 1))\n",
    "                self.problem_lens.append(len(prob) + 2)\n",
    "                self.combined_lens.append(len(prob) + len(soln) + 3)\n",
    "                prob_check.add(prob)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.combined)\n",
    "    \n",
    "    #Store both the problem length and total length\n",
    "    #Problem length later used to trim loss\n",
    "    def __getitem__(self, idx):\n",
    "        return self.combined[idx], self.problem_lens[idx], self.combined_lens[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0a44c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create datasets\n",
    "train_samples = 2048 * 1280\n",
    "valid_samples = train_samples // 5\n",
    "test_samples = train_samples // 10\n",
    "dset_args = {\"min_in_len\":8, \"max_in_len\":30, \"min_out_len\":0, \"max_out_len\":5}\n",
    "\n",
    "data = ArithDataset(train_samples + valid_samples + test_samples, **dset_args)\n",
    "trainset, validset, testset = torch.utils.data.random_split(data, [train_samples, valid_samples, test_samples], generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "print(\"Problems:\")\n",
    "for i in range(20):\n",
    "    print(decodeVocab(trainset[i][0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba64c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graph out problem lengths\n",
    "prob_lens = {}\n",
    "for problem in data:\n",
    "    if problem[1] not in prob_lens:\n",
    "        prob_lens[problem[1]] = 1\n",
    "    else:\n",
    "        prob_lens[problem[1]] += 1\n",
    "for key in prob_lens.keys():\n",
    "    prob_lens[key] /= len(data)\n",
    "lens = sorted(list(prob_lens.keys()))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.tick_params(axis='both', which='both', length=10, width=2)\n",
    "\n",
    "plt.plot(range(min(lens) - 2, max(lens) - 1), [prob_lens[i] * 100 for i in lens], linewidth=3)\n",
    "plt.title('Problem Length Distribution')\n",
    "plt.ylabel('Percentage of Problems')\n",
    "plt.ylim(0, 9)\n",
    "plt.xticks(range(min(lens) - 2, max(lens) - 1, 2))\n",
    "plt.xlabel('Problem Length')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e93880",
   "metadata": {},
   "source": [
    "# Models and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7dd37f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define basic model shells\n",
    "class Basic(nn.Module):\n",
    "    def __init__(self, model, d_model, vocab_len, reuse_embeddings = False, pad_idx=None, include_x_loss = False):\n",
    "        super(Basic, self).__init__()\n",
    "        self.model = model\n",
    "        self.d_model = d_model\n",
    "        self.vocab_len = vocab_len\n",
    "        self.embedding = nn.Embedding(vocab_len, d_model)\n",
    "        self.actor = nn.Linear(d_model, vocab_len, bias=False)\n",
    "        if reuse_embeddings:\n",
    "            self.actor.weight = self.embedding.weight\n",
    "        self.include_x_loss = include_x_loss\n",
    "        self.criteria = nn.CrossEntropyLoss(ignore_index=pad_idx)\n",
    "    \n",
    "    def forward(self, seq, seq_len):\n",
    "        output, _ = self.model(self.embedding(seq), seq_len)\n",
    "        return self.actor(output) / (self.d_model ** 0.5)\n",
    "    \n",
    "    def calcLoss(self, xy, x_len, xy_len):\n",
    "        xy = xy.to(device)\n",
    "        batch_size = xy.size(0)\n",
    "        output = self(xy, xy_len)[:, :-1]\n",
    "        if self.include_x_loss:\n",
    "            guesses = torch.reshape(output, (batch_size * (xy.size(1) - 1), self.vocab_len))\n",
    "            actual = torch.flatten(xy[:, 1:])\n",
    "            return self.criteria(guesses, actual)\n",
    "        max_y_len = torch.max(xy_len - x_len)\n",
    "        ranges = torch.arange(max_y_len) + x_len.unsqueeze(1)\n",
    "        actions = torch.reshape(output[torch.arange(batch_size).unsqueeze(1), ranges - 1], (batch_size * max_y_len, self.vocab_len))\n",
    "        actual = torch.flatten(xy[torch.arange(batch_size).unsqueeze(1), ranges])\n",
    "        return self.criteria(actions, actual)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f01f1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define different schedulers, you can get different interesting results\n",
    "#depending on scheduler used. We ended up using linear as it was the most reliable\n",
    "def decay_scheduler(steps):\n",
    "    warmup_steps = steps // 10\n",
    "    decay = 0.05 ** (1 / (steps - warmup_steps))\n",
    "    def lr_lambda(current_step):\n",
    "        if current_step < warmup_steps:\n",
    "            return current_step / warmup_steps\n",
    "        return decay ** (current_step - warmup_steps)\n",
    "    return lr_lambda\n",
    "\n",
    "def cosine_scheduler(steps):\n",
    "    warmup_steps = steps // 10\n",
    "    min_lr = 0.05\n",
    "    def lr_lambda(current_step):\n",
    "        if current_step < warmup_steps:\n",
    "            return current_step / warmup_steps\n",
    "        return min_lr + (1 - min_lr) / 2 * (1 + math.cos((current_step - warmup_steps) * math.pi / (steps - warmup_steps)))\n",
    "    return lr_lambda\n",
    "\n",
    "def linear_scheduler(steps):\n",
    "    warmup_steps = steps // 10\n",
    "    def lr_lambda(current_step):\n",
    "        if current_step < warmup_steps:\n",
    "            return current_step / warmup_steps\n",
    "        return 1.0 - ((current_step - warmup_steps) / (steps - warmup_steps))\n",
    "    return lr_lambda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c30285",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train function\n",
    "#LR Scheduling is done on a batch basis instead of epoch\n",
    "#LAMB optimizer\n",
    "#Revert to best model\n",
    "def train(model, lr, epochs=10, scheduler=linear_scheduler):\n",
    "    train_iter = DataLoader(trainset, batch_size=batch_size, shuffle=True, pin_memory=True)\n",
    "    valid_iter = DataLoader(validset, batch_size=batch_size, pin_memory=True)\n",
    "    optim = torch_optimizer.Lamb(model.parameters(), lr=lr)\n",
    "    lambdalr = torch.optim.lr_scheduler.LambdaLR(optim, lr_lambda=scheduler(epochs * len(train_iter)))\n",
    "    losses = []\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for batch_idx, batch in enumerate(train_iter):\n",
    "            print('=' * (math.floor((batch_idx / len(train_iter)) * 40) - math.floor(((batch_idx - 1) / len(train_iter)) * 40)), end = \"\")\n",
    "            optim.zero_grad()\n",
    "            loss = model.calcLoss(*batch)\n",
    "            train_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            lambdalr.step()\n",
    "        print(\">\\nEpoch {} train loss:\\t{}\".format(epoch, train_loss / len(train_iter)))\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            valid_loss = 0\n",
    "            for batch in valid_iter:\n",
    "                loss = model.calcLoss(*batch)\n",
    "                valid_loss += loss.item()\n",
    "        print(\"Epoch {} valid loss:\\t{}\".format(epoch, valid_loss / len(valid_iter)))\n",
    "        \n",
    "        losses.append(valid_loss / len(valid_iter))\n",
    "        if losses[-1] == min(losses):\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "    model.load_state_dict(torch.load('best_model.pth', weights_only=True))\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f95ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing\n",
    "def solve(model, x, x_len, max_out_len=6):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        xy = x.detach().clone().to(device)\n",
    "        xy_len = x_len.detach().clone() - 1\n",
    "        for i in range(max_out_len - 1):\n",
    "            xy_len += 1\n",
    "            output = model(xy, xy_len)\n",
    "            xy[torch.arange(xy.size(0)), xy_len] = output.argmax(2)[torch.arange(x.size(0)), xy_len - 1]\n",
    "        return xy\n",
    "\n",
    "def test(model):\n",
    "    test_iter = DataLoader(testset, batch_size=batch_size, pin_memory=True)\n",
    "    num_correct = 0\n",
    "    for batch in test_iter:\n",
    "        guesses = [decodeVocab(xy) for xy in solve(model, batch[0], batch[1], torch.max(batch[2] - batch[1]))]\n",
    "        actual = [decodeVocab(xy) for xy in batch[0]]\n",
    "        num_correct += sum([guesses[j] == actual[j] for j in range(batch_size)])\n",
    "    return num_correct / len(test_iter) / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597cd48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic feed forward for GPT, uses GELU activation\n",
    "class FeedFwd(nn.Module):\n",
    "    def __init__(self, dims, dropout=0.1, activ=nn.GELU()):\n",
    "        super(FeedFwd, self).__init__()\n",
    "        layers = [nn.Linear(dims[i], dims[i+1]) for i in range(len(dims) - 1)]\n",
    "        for i in layers:\n",
    "            nn.init.kaiming_uniform_(i.weight, mode='fan_in', nonlinearity='relu')\n",
    "            nn.init.zeros_(i.bias)\n",
    "        self.lays = nn.ModuleList(layers)\n",
    "        self.activ = activ\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for layer in self.lays[:-1]:\n",
    "            x = self.drop(self.activ(layer(x)))\n",
    "        return self.lays[-1](x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cf6afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define own LSTM in order to better manage projection and initialization\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, d_in, d_long, d_short, init_kai = True):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.d_in = d_in\n",
    "        self.d_long = d_long\n",
    "        self.d_short = d_short\n",
    "        \n",
    "        self.long0 = nn.Parameter(torch.zeros(d_long))\n",
    "        self.short0 = nn.Parameter(torch.zeros(d_short))\n",
    "        self.i_short = nn.Linear(d_short, d_long, bias=False)\n",
    "        self.i_in = nn.Linear(d_in, d_long)\n",
    "        self.f_short = nn.Linear(d_short, d_long, bias=False)\n",
    "        self.f_in = nn.Linear(d_in, d_long)\n",
    "        self.g_short = nn.Linear(d_short, d_long, bias=False)\n",
    "        self.g_in = nn.Linear(d_in, d_long)\n",
    "        self.o_short = nn.Linear(d_short, d_long, bias=False)\n",
    "        self.o_in = nn.Linear(d_in, d_long)\n",
    "        self.proj = nn.Linear(d_long, d_short)\n",
    "        self.out = nn.Linear(d_long, d_short)\n",
    "\n",
    "        nn.init.zeros_(self.i_in.bias)\n",
    "\n",
    "        nn.init.ones_(self.f_in.bias)\n",
    "        for bias in [self.i_in.bias, self.g_in.bias, self.o_in.bias, self.proj.bias, self.out.bias]:\n",
    "            nn.init.zeros_(bias)\n",
    "\n",
    "        for weight in [self.i_short.weight, self.f_short.weight, self.g_short.weight, self.o_short.weight, self.proj.weight]:\n",
    "            nn.init.orthogonal_(weight)\n",
    "            \n",
    "        if init_kai:\n",
    "            for weight in [self.i_in.weight, self.f_in.weight, self.g_in.weight, self.o_in.weight, self.out.weight]:\n",
    "                nn.init.kaiming_uniform_(weight)\n",
    "        else:\n",
    "            for weight in [self.i_in.weight, self.f_in.weight, self.g_in.weight, self.o_in.weight, self.out.weight]:\n",
    "                nn.init.normal_(weight, mean=0.0, std=0.02)\n",
    "            \n",
    "    def forward(self, x, x_len, hiddens = None):\n",
    "        batch_size = x.size(0)\n",
    "        if hiddens == None:\n",
    "            shorts = self.short0.unsqueeze(0).repeat(batch_size, 1)\n",
    "            longs = self.long0.unsqueeze(0).repeat(batch_size, 1)\n",
    "        else:\n",
    "            shorts = hiddens[0]\n",
    "            longs = hiddens[1]\n",
    "            \n",
    "        sq_len = x.size(1)\n",
    "        mask = (torch.arange(sq_len).unsqueeze(0) < x_len.unsqueeze(1)).unsqueeze(-1).to(x.device)\n",
    "        out = torch.zeros(batch_size, sq_len, self.d_short, device=x.device)\n",
    "        for sq_idx in range(sq_len):\n",
    "            i = torch.sigmoid(self.i_short(shorts) + self.i_in(x[:, sq_idx]))\n",
    "            f = torch.sigmoid(self.f_short(shorts) + self.f_in(x[:, sq_idx]))\n",
    "            g = torch.tanh(self.g_short(shorts) + self.g_in(x[:, sq_idx]))\n",
    "            o = torch.sigmoid(self.o_short(shorts) + self.o_in(x[:, sq_idx]))\n",
    "            longs = (f * longs + i * g) * mask[:, sq_idx] + longs * ~mask[:, sq_idx]\n",
    "            shorts = self.proj(o * longs) * mask[:, sq_idx] + shorts * ~mask[:, sq_idx]\n",
    "            out[:, sq_idx] = self.out(o * longs)\n",
    "        return out, (shorts, longs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c2ed2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define own multi-head self attention.\n",
    "#Necessary to work nice with recurrence + autoregressive caching\n",
    "float_min = torch.finfo(torch.float32).min\n",
    "class MHSA(nn.Module):\n",
    "    def __init__(self, d_model, d_sa, n_head, dropout = 0.1, rope=False):\n",
    "        super(MHSA, self).__init__()\n",
    "        self.n_head = n_head\n",
    "        self.d_model = d_model\n",
    "        self.d_sa = d_sa\n",
    "        self.d_key = d_sa // n_head\n",
    "        self.q = nn.Linear(d_model, d_sa)\n",
    "        self.k = nn.Linear(d_model, d_sa)\n",
    "        self.v = nn.Linear(d_model, d_sa)\n",
    "        for lin in [self.k, self.q, self.v]:\n",
    "            nn.init.zeros_(lin.bias)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.sa_lin = nn.Linear(d_sa, d_model)\n",
    "        if rope:\n",
    "            self.rope = torchtune.modules.RotaryPositionalEmbeddings(dim=self.d_key)\n",
    "        else:\n",
    "            self.rope = None\n",
    "    \n",
    "    def parallel(self, src, mem, mask=None):\n",
    "        batch_size = src.size(0)\n",
    "        src_sq_len = src.size(1)\n",
    "        mem_sq_len = mem.size(1)\n",
    "        if self.rope != None:\n",
    "            ks = self.rope(self.k(mem).view(batch_size, mem_sq_len, self.n_head, self.d_key)).transpose(1, 2)\n",
    "            qs = self.rope(self.q(src).view(batch_size, src_sq_len, self.n_head, self.d_key)).transpose(1, 2)\n",
    "        else:\n",
    "            ks = self.k(mem).view(batch_size, mem_sq_len, self.n_head, self.d_key).transpose(1, 2)\n",
    "            qs = self.q(src).view(batch_size, src_sq_len, self.n_head, self.d_key).transpose(1, 2)\n",
    "        vs = self.v(mem).view(batch_size, mem_sq_len, self.n_head, self.d_key).transpose(1, 2)\n",
    "        \n",
    "        dots = torch.matmul(qs, ks.transpose(-1, -2)) / math.sqrt(self.d_key)\n",
    "        if mask != None:\n",
    "            dots[~(mask.unsqueeze(1).repeat(1, self.n_head, 1, 1))] = float_min\n",
    "        attn_weight = self.dropout(nn.Softmax(dim = -1)(dots))\n",
    "        attns = torch.matmul(attn_weight, vs).transpose(1, 2).contiguous().view(batch_size, src_sq_len, self.d_sa)\n",
    "        return self.sa_lin(attns)\n",
    "        \n",
    "    def autoreg(self, incoming, ks, vs, mask=None):\n",
    "        batch_size = incoming.size(0)\n",
    "        if self.rope != None:\n",
    "            qs = self.rope(self.q(incoming).view(batch_size, 1, self.n_head, self.d_key), input_pos=torch.tensor(len(ks)).unsqueeze(0).repeat(batch_size, 1)).squeeze(1)\n",
    "        else:\n",
    "            qs = self.q(incoming).view(batch_size, self.n_head, self.d_key)\n",
    "        dots = torch.sum(qs * torch.stack(ks), dim = -1) / math.sqrt(self.d_key)\n",
    "        if mask != None:\n",
    "            dots[~mask] = float_min\n",
    "        attn_weight = self.dropout(nn.Softmax(dim = -3)(dots))\n",
    "        return self.sa_lin(torch.sum(attn_weight.unsqueeze(-1) * torch.stack(vs), dim = (0)).view(batch_size, self.d_sa))\n",
    "    \n",
    "    def reg_kvs(self, incoming, ks, vs):\n",
    "        if self.rope != None:\n",
    "            ks.append(self.rope(self.k(incoming).view(incoming.size(0), 1, self.n_head, self.d_key), input_pos=torch.tensor(len(ks)).unsqueeze(0).repeat(incoming.size(0), 1)).squeeze(1))\n",
    "        else:\n",
    "            ks.append(self.k(incoming).view(incoming.size(0), self.n_head, self.d_key))\n",
    "        vs.append(self.v(incoming).view(incoming.size(0), self.n_head, self.d_key))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8e852d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recurrent Transformer\n",
    "class ReTran(nn.Module):\n",
    "    def __init__(self, ffwd_dim, d_sa, d_model, n_head, n_lay, dropout = 0.1):\n",
    "        super(ReTran, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.n_lay = n_lay\n",
    "        self.lstms = nn.ParameterList([LSTM(d_model, ffwd_dim, d_model, init_kai=False) for _ in range(n_lay)])\n",
    "        self.sas = nn.ParameterList([MHSA(d_model, d_sa, n_head, rope=True, dropout=dropout) for _ in range (n_lay)])\n",
    "        for sa in self.sas:\n",
    "            sa.apply(_init_gpt2)\n",
    "        self.sa_h0s = nn.ParameterList([nn.Parameter(torch.zeros(d_model)) for _ in range(n_lay)])\n",
    "        self.sa_norms = nn.ParameterList([nn.LayerNorm(d_model) for _ in range(n_lay)])\n",
    "        self.ffwd_norms = nn.ParameterList([nn.LayerNorm(d_model) for _ in range(n_lay)])\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, x_len):\n",
    "        batch_size = x.size(0)\n",
    "        sq_len = x.size(1)\n",
    "        pad_mask = torch.arange(sq_len).unsqueeze(0) < x_len.unsqueeze(1)\n",
    "        lstm_hiddens = [None for _ in range(self.n_lay)]\n",
    "        out = torch.zeros((batch_size, sq_len, self.d_model), device = x.device)\n",
    "        ks = [[] for _ in range(self.n_lay)]\n",
    "        vs = [[] for _ in range(self.n_lay)]\n",
    "        \n",
    "        for layer in range(self.n_lay):\n",
    "            self.sas[layer].reg_kvs(self.sa_h0s[layer].unsqueeze(0).repeat(batch_size, 1), ks[layer], vs[layer])\n",
    "        \n",
    "        for sq_idx in range(sq_len):\n",
    "            curr = x[:, sq_idx]\n",
    "            for layer in range(self.n_lay):\n",
    "                curr = self.sa_norms[layer](self.dropout(self.sas[layer].autoreg(curr, ks[layer], vs[layer])) + curr)\n",
    "                lstm_out, lstm_hiddens[layer] = self.lstms[layer](curr.unsqueeze(1), pad_mask[:, sq_idx], lstm_hiddens[layer])\n",
    "                curr = self.ffwd_norms[layer](self.dropout(lstm_out.squeeze(1)) + curr)\n",
    "                self.sas[layer].reg_kvs(curr, ks[layer], vs[layer])\n",
    "            out[:, sq_idx] = curr\n",
    "        \n",
    "        return out, (out, lstm_hiddens, ks, vs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8b4cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GPT definition          \n",
    "class GPT(nn.Module):\n",
    "    def __init__(self, d_ffwd, d_sa, d_model, n_head, n_lay, activ=nn.GELU(), dropout = 0.1):\n",
    "        super(GPT, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.n_lay = n_lay\n",
    "        self.sas = nn.ParameterList([MHSA(d_model, d_sa, n_head, dropout=dropout, rope=True) for _ in range(n_lay)])\n",
    "        self.ffwds = nn.ParameterList([FeedFwd([d_model, d_ffwd, d_model], dropout=dropout, activ=activ) for _ in range(n_lay)])\n",
    "        self.sa_norms = nn.ParameterList([nn.LayerNorm(d_model) for _ in range(n_lay)])\n",
    "        self.ffwd_norms = nn.ParameterList([nn.LayerNorm(d_model) for _ in range(n_lay)])\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, x_len):\n",
    "        batch_size = x.size(0)\n",
    "        sq_len = x.size(1)\n",
    "        src_mask = (torch.arange(sq_len).unsqueeze(0) < x_len.unsqueeze(1)).to(x.device)\n",
    "        mask = src_mask.unsqueeze(1).repeat(1, sq_len, 1) & torch.tril(torch.ones(sq_len, sq_len).unsqueeze(0).repeat(batch_size, 1, 1)).bool().to(x.device)\n",
    "        for layer in range(self.n_lay):\n",
    "            x = self.sa_norms[layer](x + self.dropout(self.sas[layer].parallel(x, x, mask=mask)))\n",
    "            x = self.ffwd_norms[layer](x + self.dropout(self.ffwds[layer](x)))\n",
    "        return x, (x, src_mask)\n",
    "\n",
    "#Uses initialization from GPT-2, centered around 0 with small std\n",
    "def _init_gpt2(module):\n",
    "    if isinstance(module, nn.Linear):\n",
    "        torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "        if module.bias is not None:\n",
    "            torch.nn.init.zeros_(module.bias)\n",
    "    elif isinstance(module, nn.Embedding):\n",
    "        torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "    elif isinstance(module, nn.LayerNorm):\n",
    "        if module.weight is not None:\n",
    "            torch.nn.init.ones_(module.weight)\n",
    "        if module.bias is not None:\n",
    "            torch.nn.init.zeros_(module.bias)\n",
    "            \n",
    "def init_sa_lin(model):\n",
    "    for pn, p in model.named_parameters():\n",
    "        if pn.endswith('sa_lin.weight'):\n",
    "            torch.nn.init.normal_(p, mean = 0.0, std=0.02/math.sqrt(2 * model.n_lay))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e6fb55-975b-4677-bece-5e919b316688",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayLSTM(nn.Module):\n",
    "    def __init__(self, ffwd_dim, d_model, n_lay, dropout = 0.1):\n",
    "        super(MultiLayLSTM, self).__init__()\n",
    "        self.n_lay = n_lay\n",
    "        self.d_model = d_model\n",
    "        self.lstms = nn.ParameterList([LSTM(d_model, ffwd_dim, d_model) for _ in range(n_lay)])\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x, x_len):\n",
    "        batch_size = x.size(0)\n",
    "        sq_len = x.size(1)\n",
    "        pad_mask = torch.arange(sq_len).unsqueeze(0) < x_len.unsqueeze(1)\n",
    "        lstm_hiddens = [None for _ in range(self.n_lay)]\n",
    "        out = torch.zeros((batch_size, sq_len, self.d_model), device = x.device)\n",
    "\n",
    "        for sq_idx in range(sq_len):\n",
    "            curr = x[:, sq_idx]\n",
    "            for layer in range(self.n_lay):\n",
    "                lstm_out, lstm_hiddens[layer] = self.lstms[layer](curr.unsqueeze(1), pad_mask[:, sq_idx], lstm_hiddens[layer])\n",
    "                if layer != self.n_lay - 1:\n",
    "                    curr = self.dropout(lstm_out.squeeze(1))\n",
    "                else:\n",
    "                    curr = lstm_out.squeeze(1)\n",
    "            out[:, sq_idx] = curr\n",
    "\n",
    "        return (out, lstm_hiddens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e50add2",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bd8cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Large batch size due to LAMB\n",
    "batch_size = 2048\n",
    "dropout = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e55f6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "retran_params = []\n",
    "retran_losses = []\n",
    "retran_acc = []\n",
    "retran_time = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389cf42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Small retran\n",
    "d_model = 16\n",
    "d_ffwd = 64\n",
    "d_sa = 16\n",
    "n_lay = 3\n",
    "n_head = 8\n",
    "basic_retran = Basic(ReTran(d_ffwd, d_sa, d_model, n_head, n_lay, dropout=dropout), d_model, len(vocab), False, vocab.index(PAD)).to(device)\n",
    "init_sa_lin(basic_retran.model)\n",
    "retran_params.append(sum(p.numel() for p in basic_retran.parameters()))\n",
    "print(\"Total small retran params: \", retran_params[-1])\n",
    "basic_retran_time, basic_retran_valid_losses = timer(train, basic_retran, lr=0.008)\n",
    "retran_time.append(basic_retran_time)\n",
    "retran_losses.append(min(basic_retran_valid_losses))\n",
    "retran_acc.append(test(basic_retran))\n",
    "print(\"Proportion small retran test case correct: \", retran_acc[-1])\n",
    "print(\"Time\", retran_time[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d34032",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Medium retran\n",
    "d_model = 32\n",
    "d_ffwd = 128\n",
    "d_sa = 32\n",
    "n_lay = 4\n",
    "n_head = 8\n",
    "basic_retran = Basic(ReTran(d_ffwd, d_sa, d_model, n_head, n_lay, dropout=dropout), d_model, len(vocab), False, vocab.index(PAD)).to(device)\n",
    "init_sa_lin(basic_retran.model)\n",
    "retran_params.append(sum(p.numel() for p in basic_retran.parameters()))\n",
    "print(\"Total medium retran params: \", retran_params[-1])\n",
    "basic_retran_time, basic_retran_valid_losses = timer(train, basic_retran, lr=0.008)\n",
    "retran_time.append(basic_retran_time)\n",
    "retran_losses.append(min(basic_retran_valid_losses))\n",
    "retran_acc.append(test(basic_retran))\n",
    "print(\"Proportion medium retran test case correct: \", retran_acc[-1])\n",
    "print(\"Time\", retran_time[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3580ab5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Large retran\n",
    "d_model = 64\n",
    "d_ffwd = 256\n",
    "d_sa = 64\n",
    "n_lay = 6\n",
    "n_head = 8\n",
    "basic_retran = Basic(ReTran(d_ffwd, d_sa, d_model, n_head, n_lay, dropout=dropout), d_model, len(vocab), False, vocab.index(PAD)).to(device)\n",
    "init_sa_lin(basic_retran.model)\n",
    "retran_params.append(sum(p.numel() for p in basic_retran.parameters()))\n",
    "print(\"Total large retran params: \", retran_params[-1])\n",
    "basic_retran_time, basic_retran_valid_losses = timer(train, basic_retran, lr=0.008)\n",
    "retran_time.append(basic_retran_time)\n",
    "retran_losses.append(min(basic_retran_valid_losses))\n",
    "retran_acc.append(test(basic_retran))\n",
    "print(\"Proportion large retran test case correct: \", retran_acc[-1])\n",
    "print(\"Time\", retran_time[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e986be75",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_params = []\n",
    "gpt_losses = []\n",
    "gpt_acc = []\n",
    "gpt_time = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0910718",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Small GPT\n",
    "d_model = 32\n",
    "d_ffwd = 128\n",
    "d_sa = 32\n",
    "n_lay = 3\n",
    "n_head = 8\n",
    "basic_gpt = Basic(GPT(d_ffwd, d_sa, d_model, n_head, n_lay, dropout=dropout), d_model, len(vocab), False, vocab.index(PAD)).to(device)\n",
    "basic_gpt.apply(_init_gpt2)\n",
    "init_sa_lin(basic_gpt.model)\n",
    "gpt_params.append(sum(p.numel() for p in basic_gpt.parameters()))\n",
    "print(\"Total small GPT params: \", gpt_params[-1])\n",
    "#We performed a grid search to find optimal lr for each architecture.\n",
    "basic_gpt_time, basic_gpt_valid_losses = timer(train, basic_gpt, lr=0.01)\n",
    "gpt_time.append(basic_gpt_time)\n",
    "gpt_losses.append(min(basic_gpt_valid_losses))\n",
    "gpt_acc.append(test(basic_gpt))\n",
    "print(\"Proportion small GPT test case correct: \", gpt_acc[-1])\n",
    "print(\"Time\", gpt_time[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0e31bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Medium GPT\n",
    "d_model = 64\n",
    "d_ffwd = 256\n",
    "d_sa = 64\n",
    "n_lay = 4\n",
    "n_head = 8\n",
    "basic_gpt = Basic(GPT(d_ffwd, d_sa, d_model, n_head, n_lay, dropout=dropout), d_model, len(vocab), False, vocab.index(PAD)).to(device)\n",
    "basic_gpt.apply(_init_gpt2)\n",
    "init_sa_lin(basic_gpt.model)\n",
    "gpt_params.append(sum(p.numel() for p in basic_gpt.parameters()))\n",
    "print(\"Total medium GPT params: \", gpt_params[-1])\n",
    "basic_gpt_time, basic_gpt_valid_losses = timer(train, basic_gpt, lr=0.01)\n",
    "gpt_time.append(basic_gpt_time)\n",
    "gpt_losses.append(min(basic_gpt_valid_losses))\n",
    "gpt_acc.append(test(basic_gpt))\n",
    "print(\"Proportion medium GPT test case correct: \", gpt_acc[-1])\n",
    "print(\"Time\", gpt_time[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9248d786",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Large GPT\n",
    "d_model = 128\n",
    "d_ffwd = 512\n",
    "d_sa = 128\n",
    "n_lay = 6\n",
    "n_head = 8\n",
    "basic_gpt = Basic(GPT(d_ffwd, d_sa, d_model, n_head, n_lay, dropout=dropout), d_model, len(vocab), False, vocab.index(PAD)).to(device)\n",
    "basic_gpt.apply(_init_gpt2)\n",
    "init_sa_lin(basic_gpt.model)\n",
    "gpt_params.append(sum(p.numel() for p in basic_gpt.parameters()))\n",
    "print(\"Total large GPT params: \", gpt_params[-1])\n",
    "basic_gpt_time, basic_gpt_valid_losses = timer(train, basic_gpt, lr=0.01)\n",
    "gpt_time.append(basic_gpt_time)\n",
    "gpt_losses.append(min(basic_gpt_valid_losses))\n",
    "gpt_acc.append(test(basic_gpt))\n",
    "print(\"Proportion large GPT test case correct: \", gpt_acc[-1])\n",
    "print(\"Time\", gpt_time[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb6dc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_params = []\n",
    "lstm_losses = []\n",
    "lstm_acc = []\n",
    "lstm_time = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763445d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Small LSTM\n",
    "d_model = 16\n",
    "d_ffwd = 64\n",
    "n_lay = 3\n",
    "basic_lstm = Basic(MultiLayLSTM(d_ffwd, d_model, n_lay, dropout=dropout), d_model, len(vocab), False, vocab.index(PAD)).to(device)\n",
    "lstm_params.append(sum(p.numel() for p in basic_lstm.parameters()))\n",
    "print(\"Total small lstm params: \", lstm_params[-1])\n",
    "basic_lstm_time, basic_lstm_valid_losses = timer(train, basic_lstm, lr=0.006)\n",
    "lstm_losses.append(min(basic_lstm_valid_losses))\n",
    "lstm_time.append(basic_lstm_time)\n",
    "lstm_acc.append(test(basic_lstm))\n",
    "print(\"Proportion small lstm test case correct: \", lstm_acc[-1])\n",
    "print(\"Time\", lstm_time[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda050a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Medium LSTM\n",
    "d_model = 32\n",
    "d_ffwd = 128\n",
    "n_lay = 4\n",
    "basic_lstm = Basic(MultiLayLSTM(d_ffwd, d_model, n_lay, dropout=dropout), d_model, len(vocab), False, vocab.index(PAD)).to(device)\n",
    "lstm_params.append(sum(p.numel() for p in basic_lstm.parameters()))\n",
    "print(\"Total medium lstm params: \", lstm_params[-1])\n",
    "basic_lstm_time, basic_lstm_valid_losses = timer(train, basic_lstm, lr=0.006)\n",
    "lstm_losses.append(min(basic_lstm_valid_losses))\n",
    "lstm_time.append(basic_lstm_time)\n",
    "lstm_acc.append(test(basic_lstm))\n",
    "print(\"Proportion medium lstm test case correct: \", lstm_acc[-1])\n",
    "print(\"Time\", lstm_time[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bd57e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Large LSTM\n",
    "d_model = 64\n",
    "d_ffwd = 256\n",
    "n_lay = 6\n",
    "basic_lstm = Basic(MultiLayLSTM(d_ffwd, d_model, n_lay, dropout=dropout), d_model, len(vocab), False, vocab.index(PAD)).to(device)\n",
    "lstm_params.append(sum(p.numel() for p in basic_lstm.parameters()))\n",
    "print(\"Total large lstm params: \", lstm_params[-1])\n",
    "basic_lstm_time, basic_lstm_valid_losses = timer(train, basic_lstm, lr=0.006)\n",
    "lstm_losses.append(min(basic_lstm_valid_losses))\n",
    "lstm_time.append(basic_lstm_time)\n",
    "lstm_acc.append(test(basic_lstm))\n",
    "print(\"Proportion large lstm test case correct: \", lstm_acc[-1])\n",
    "print(\"Time\", lstm_time[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801d2464",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91e10c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We used the commented code to test GPT-4o performance\n",
    "#You can either trust us and leave it commented, or try it out for yourself\n",
    "#Running the commented code requires properly setting up an OpenAI API account at https://platform.openai.com/\n",
    "gpto_perf = 55.68\n",
    "\n",
    "_ = \"\"\"\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "\n",
    "client = OpenAI()\n",
    "class MathAnswer(BaseModel):\n",
    "    answer: int\n",
    "\n",
    "gpto_total = 10000\n",
    "gpto_correct = 0\n",
    "for prob in range(gpto_total):\n",
    "    xy = decodeVocab(testset[prob][0])\n",
    "    split = xy.index('=') + 1\n",
    "    x = xy[:split]\n",
    "    y = xy[split:]\n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o\",\n",
    "        temperature = 0.0,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Answer the math question.\"},\n",
    "            {\"role\": \"user\", \"content\": str(x)},\n",
    "        ],\n",
    "        response_format=MathAnswer,\n",
    "    )\n",
    "    ans = completion.choices[0].message.parsed.answer\n",
    "    if y == str(ans):\n",
    "        gpto_correct += 1\n",
    "    if prob % 100 == 0:\n",
    "        print(\"Through\", prob, \"problems,\", gpto_correct / (prob + 1) * 100, \"% correct\")\n",
    "print(\"Final\", gpto_correct / gpto_total * 100, \"% correct\")\n",
    "gpto_perf = gpto_correct / gpto_total * 100\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae31c916",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.tick_params(axis='both', which='both', length=10, width=2)\n",
    "\n",
    "plt.plot(retran_params, [acc * 100 for acc in retran_acc], label='ReTran', marker='x', markersize=15, linewidth=3)\n",
    "plt.plot(lstm_params, [acc * 100 for acc in lstm_acc], label=\"LSTM\", marker='x', markersize=15, linewidth=3)\n",
    "plt.plot(gpt_params, [acc * 100 for acc in gpt_acc], label='GPT', marker='x', markersize=15, linewidth=3)\n",
    "plt.plot([min(retran_params + lstm_params + gpt_params), max(retran_params + lstm_params + gpt_params)], [gpto_perf, gpto_perf], label='GPT-4o', linestyle=':', linewidth=3)\n",
    "\n",
    "plt.title('Test Accuracy over Parameter Count')\n",
    "\n",
    "plt.xscale('log')\n",
    "plt.ylim(0, 100)\n",
    "plt.ylabel('Test Accuracy (Percent)')\n",
    "plt.xlabel('Parameter Count')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35efc945",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Break out test accuracy by problem length\n",
    "def test_lens(model, dataset):\n",
    "    test_iter = DataLoader(dataset, batch_size=batch_size, pin_memory=True)\n",
    "    num_correct = {}\n",
    "    total = {}\n",
    "    for batch in test_iter:\n",
    "        guesses = [decodeVocab(xy) for xy in solve(model, batch[0], batch[1], torch.max(batch[2] - batch[1]))]\n",
    "        actual = [decodeVocab(xy) for xy in batch[0]]\n",
    "        for j in range(batch_size):\n",
    "            if batch[1][j].item() not in total.keys():\n",
    "                total[batch[1][j].item()] = 0\n",
    "                num_correct[batch[1][j].item()] = 0\n",
    "            if guesses[j] == actual[j]:\n",
    "                num_correct[batch[1][j].item()] += 1\n",
    "            total[batch[1][j].item()] += 1\n",
    "    for key in num_correct.keys():\n",
    "        num_correct[key] /= total[key]\n",
    "    return num_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf064216",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tests the last trained model of each architecture.\n",
    "#If you run the notebook linearly, this will be the largest from each architecture\n",
    "#If desired, run cells in a different order to compare different sized models\n",
    "gpt_test_lens = test_lens(basic_gpt, testset)\n",
    "retran_test_lens = test_lens(basic_retran, testset)\n",
    "lstm_test_lens = test_lens(basic_lstm, testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe9dc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate out of distribution data\n",
    "long_data = ArithDataset(2048 * 64, min_in_len=31, max_in_len=40, min_out_len=0, max_out_len=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736b0a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add in out of distribution data\n",
    "gpt_test_lens |= test_lens(basic_gpt, long_data)\n",
    "retran_test_lens |= test_lens(basic_retran, long_data)\n",
    "lstm_test_lens |= test_lens(basic_lstm, long_data)\n",
    "lens = sorted(list(gpt_test_lens.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6a51da",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.tick_params(axis='both', which='both', length=10, width=2)\n",
    "\n",
    "plt.plot([l-2 for l in lens], [retran_test_lens[l] * 100 for l in lens], label='Large ReTran', linewidth=3)\n",
    "plt.plot([l-2 for l in lens], [lstm_test_lens[l] * 100 for l in lens], label='Large LSTM', linewidth=3)\n",
    "plt.plot([l-2 for l in lens], [gpt_test_lens[l] * 100 for l in lens], label='Large GPT', linewidth=3)\n",
    "\n",
    "plt.title('Test Accuracy over Problem Lengths')\n",
    "plt.ylabel('Test Accuracy (Percent)')\n",
    "plt.xlabel('Problem length')\n",
    "plt.xticks(range(min(lens) - 2, max(lens) - 1, 2))\n",
    "plt.axvspan(30.5, max(lens)-2, color='gray', alpha=0.3, label='Out of distribution')\n",
    "\n",
    "plt.ylim(0, 100)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cf23e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.tick_params(axis='both', which='both', length=10, width=2)\n",
    "plt.plot(retran_params, retran_losses, label='ReTran', marker='x', markersize=15, linewidth=3)\n",
    "plt.plot(lstm_params, lstm_losses, label=\"LSTM\", marker='x', markersize=15, linewidth=3)\n",
    "plt.plot(gpt_params, gpt_losses, label='GPT', marker='x', markersize=15, linewidth=3)\n",
    "\n",
    "plt.title('Final Validation Losses over Parameter Count')\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.xscale('log')\n",
    "\n",
    "formatter = ScalarFormatter()\n",
    "formatter.set_scientific(False)\n",
    "plt.gca().yaxis.set_major_formatter(formatter)\n",
    "plt.gca().yaxis.set_minor_formatter(formatter)\n",
    "\n",
    "\n",
    "plt.ylabel('Final Validation Loss')\n",
    "plt.xlabel('Parameter Count')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263436ea-b2e2-43d7-8f0c-7354bdfc5b77",
   "metadata": {},
   "source": [
    "Copyright © 2025 anonymous\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
